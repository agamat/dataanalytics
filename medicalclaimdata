#Read data into R. This data contains medical information of 458005 patients on the interval 2008-2009 inclusing their ages, diseases they were diagnosed with and their medical claims. The patients are grouped into 5 branches according to the amount of their medical claim.
claims <- read.csv("ClaimsData.csv")

table(claims$bucket2009)/(nrow(claims)) #Check the proportion of patients in each branch

library(caTools) #Load R package that contains the CART function

spl <- sample.split(claims$bucket2009, SplitRatio=0.6) #Split the data into trainign and testing set with 60% of the data in the training set. The model created using the training set will be compared with the testing set and it's accuracy measured.

train <- subset(claims, spl==TRUE)
test <- subset(claims, spl==FALSE)

table(test$bucket2009, test$bucket2008) #Measure baseline accuracy by making a classification matrix

(110138+10721+2774+1539+104)/(nrow(test))

penaltymatrix <- matrix(c(0,1,2,3,4,2,0,1,2,3,4,2,0,1,2,6,4,2,0,1,8,6,4,2,0), byrow=TRUE, nrow=5) #Create penalty matrix

as.matrix(table(test$bucket2009, test$bucket2008))*penaltymatrix #Convert classification matrix into a data matrix and then calculating the penalty error of the baseline model by multiplying the penalty matrix with data matrix.

sum(as.matrix(table(test$bucket2009, test$bucket2008))*penaltymatrix)/nrow(test) #Calculate penalty error

library(rpart) #Load package for RPART function
library(rpart.plot) #Load package for RPART.PLOT function

#Compute rpart model. Cross validation not shown
claimstree <- rpart(bucket2009 ~ age+arthritis+alzheimers+cancer+copd+depression+diabetes+heart.failure+ihd+kidney+osteoporosis+stroke+bucket2008+reimbursement2008, data=train, method="class", cp=0.00005)
prp(claimstree) #Plot model
predicttest <- predict(claimstree, newdata=test, type="class") #Use model to predict testing set.

#Compute model accuracy
table(test$bucket2009, predicttest)
(114141+16102+118+201+0)/nrow(test)

as.matrix(table(test$bucket2009, predicttest))*penaltymatrix #Compute penalty error

sum(as.matrix(table(test$bucket2009, predicttest))*penaltymatrix)/nrow(test) #Compute penalty error. Model accuracy improved, but penalty error also improved. This is because very few observations in high-risk class.

#Create another model using penalty matrix as a reference. Now R knows that we give some types of error more importance than others
claimstree <- rpart(bucket2009 ~ age+arthritis+alzheimers+cancer+copd+depression+diabetes+heart.failure+ihd+kidney+osteoporosis+stroke+bucket2008+reimbursement2008, data=train, method="class", cp=0.00005, parms=list(loss=penaltymatrix))

predicttest <- predict(claimstree, newdata=test, type="class") #Predict on test set using new rpart model
table(test$bucket2009, predicttest) #Measure accuracy
(94310+18942+4692+636+2)/nrow(test)
sum(as.matrix(table(test$bucket2009, predicttest))*penaltymatrix)/nrow(test) #Measure penalty error. Now, accuracy is lower but penalty error is also lower. This model is preferred since it mitigates risk instead of focusing on accuracy.

